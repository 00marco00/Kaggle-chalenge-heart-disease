type = "classification")  # Spécifier le type de modèle
# Affichage du résumé du modèle
print(modele_rf)
# Pour voir l'importance des variables
importance(modele_rf)
library(ggplot2)
# Calcul de l'importance des variables et conversion en dataframe
varImp <- importance(modele_rf)
importance_df <- as.data.frame(varImp)
# Création du graphique d'importance des variables
ggplot(importance_df, aes(x = reorder(row.names(importance_df), MeanDecreaseGini), y = MeanDecreaseGini)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +  # Inverser les axes pour une meilleure lisibilité
labs(x = "Variables", y = "Importance", title = "Importance des variables dans le modèle Random Forest") +
theme_minimal()
library(caret)
library(ada)
# Spécification du contrôle de la formation avec validation croisée, par exemple
#fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
fitControl <- trainControl(method = "cv", number = 5)  # Utilisez une validation croisée simple avec moins de plis
# Ajustement du modèle AdaBoost
modele_ada <- train(HeartDisease ~ Age+ Sex + ChestPainType + MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope,
data = trainData,
method = "ada",
trControl = fitControl,
tuneLength = 5) #5
# Résumé du modèle
print(modele_ada)
# Prédiction sur l'ensemble de test
predictions <- predict(modele_ada, newdata = testData)
# Calcul de l'exactitude
confusionMatrix <- confusionMatrix(predictions, testData$HeartDisease)
accuracy <- sum(diag(confusionMatrix$table)) / sum(confusionMatrix$table)
classification_error <- 1 - accuracy
# Affichage de l'exactitude et de l'erreur de classification
print(paste("Exactitude :", accuracy))
print(paste("Erreur de classification :", classification_error))
library(caret)
library(ada)
# Spécification du contrôle de la formation avec validation croisée, par exemple
#fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
fitControl <- trainControl(method = "cv", number = 5)  # Utilisez une validation croisée simple avec moins de plis
# Ajustement du modèle AdaBoost
modele_ada <- train(HeartDisease ~ Sex + ChestPainType + MaxHR + Cholesterol + ExerciseAngina+ ExerciseAngina + Oldpeak + ST_Slope,
data = trainData,
method = "ada",
trControl = fitControl,
tuneLength = 5) #5
# Résumé du modèle
print(modele_ada)
# Prédiction sur l'ensemble de test
predictions <- predict(modele_ada, newdata = testData)
# Calcul de l'exactitude
confusionMatrix <- confusionMatrix(predictions, testData$HeartDisease)
accuracy <- sum(diag(confusionMatrix$table)) / sum(confusionMatrix$table)
classification_error <- 1 - accuracy
# Affichage de l'exactitude et de l'erreur de classification
print(paste("Exactitude :", accuracy))
print(paste("Erreur de classification :", classification_error))
library(caret)
library(ada)
# Spécification du contrôle de la formation avec validation croisée, par exemple
#fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
fitControl <- trainControl(method = "cv", number = 5)  # Utilisez une validation croisée simple avec moins de plis
# Ajustement du modèle AdaBoost
modele_ada <- train(HeartDisease ~ Sex + ChestPainType + MaxHR + Cholesterol + ST_Slope + ExerciseAngina + Oldpeak + ST_Slope,
data = trainData,
method = "ada",
trControl = fitControl,
tuneLength = 5) #5
# Résumé du modèle
print(modele_ada)
# Prédiction sur l'ensemble de test
predictions <- predict(modele_ada, newdata = testData)
# Calcul de l'exactitude
confusionMatrix <- confusionMatrix(predictions, testData$HeartDisease)
accuracy <- sum(diag(confusionMatrix$table)) / sum(confusionMatrix$table)
classification_error <- 1 - accuracy
# Affichage de l'exactitude et de l'erreur de classification
print(paste("Exactitude :", accuracy))
print(paste("Erreur de classification :", classification_error))
library(caret)
library(ada)
# Spécification du contrôle de la formation avec validation croisée, par exemple
#fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
fitControl <- trainControl(method = "cv", number = 5)  # Utilisez une validation croisée simple avec moins de plis
# Ajustement du modèle AdaBoost
modele_ada <- train(HeartDisease ~ Sex + ChestPainType + MaxHR + Cholesterol + ExerciseAngina + ExerciseAngina + Oldpeak + ST_Slope,
data = trainData,
method = "ada",
trControl = fitControl,
tuneLength = 5) #5
# Résumé du modèle
print(modele_ada)
# Prédiction sur l'ensemble de test
predictions <- predict(modele_ada, newdata = testData)
# Calcul de l'exactitude
confusionMatrix <- confusionMatrix(predictions, testData$HeartDisease)
accuracy <- sum(diag(confusionMatrix$table)) / sum(confusionMatrix$table)
classification_error <- 1 - accuracy
# Affichage de l'exactitude et de l'erreur de classification
print(paste("Exactitude :", accuracy))
print(paste("Erreur de classification :", classification_error))
data = data_clean
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
data$HeartDisease <- factor(data$HeartDisease)
# On sépare les données en partie pour l'entrainement et une pour les tests
pourcentageTraining = 0.9
nSamples = nrow(data)
#set.seed(123)
index <- sample(1:nrow(data), size = pourcentageTraining * nrow(data), replace = FALSE)
trainData <- data[index, ]
testData <- data[-index, ]
bp = boxplot(data[, -ncol(data)], plot = FALSE)
data_clean = data
for (i in 1:(ncol(data))){
# On a beaucoup moins de femmes que d'hommes donc il faut faire attention à ce que le code ne supprime pas toutes les donnés provenant de patientes
if(names(data_clean[i]) == "Sex"){
next
}
valeurs_aberrantes = bp$out[which(bp$group == i)]
data_clean = data_clean[!data_clean[, i] %in% valeurs_aberrantes, ]
}
for (i in 1:(ncol(data_clean))) {
boxplot(data_clean[, i], main = names(data_clean[i]))
}
rm(i)
bp = boxplot(data[, -ncol(data)], plot = FALSE)
data_clean = data
for (i in 1:(ncol(data))){
# On a beaucoup moins de femmes que d'hommes donc il faut faire attention à ce que le code ne supprime pas toutes les donnés provenant de patientes
if(names(data_clean[i]) == "Sex"){
next
}
valeurs_aberrantes = bp$out[which(bp$group == i)]
data_clean = data_clean[!data_clean[, i] %in% valeurs_aberrantes, ]
}
for (i in 1:(ncol(data_clean))) {
boxplot(data_clean[, i], main = names(data_clean[i]))
}
rm(i)
data = data_clean
data$HeartDisease <- factor(data$HeartDisease)
# On sépare les données en partie pour l'entrainement et une pour les tests
pourcentageTraining = 0.9
nSamples = nrow(data)
#set.seed(123)
index <- sample(1:nrow(data), size = pourcentageTraining * nrow(data), replace = FALSE)
trainData <- data[index, ]
testData <- data[-index, ]
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
data$HeartDisease <- factor(data$HeartDisease)
# On sépare les données en partie pour l'entrainement et une pour les tests
pourcentageTraining = 0.9
nSamples = nrow(data)
set.seed(123)
index <- sample(1:nrow(data), size = pourcentageTraining * nrow(data), replace = FALSE)
trainData <- data[index, ]
testData <- data[-index, ]
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
data$HeartDisease <- factor(data$HeartDisease)
# On sépare les données en partie pour l'entrainement et une pour les tests
pourcentageTraining = 0.9
nSamples = nrow(data)
#set.seed(123)
index <- sample(1:nrow(data), size = pourcentageTraining * nrow(data), replace = FALSE)
trainData <- data[index, ]
testData <- data[-index, ]
data$HeartDisease <- factor(data$HeartDisease)
# On sépare les données en partie pour l'entrainement et une pour les tests
pourcentageTraining = 0.9
nSamples = nrow(data)
#set.seed(123)
index <- sample(1:nrow(data), size = pourcentageTraining * nrow(data), replace = FALSE)
trainData <- data[index, ]
testData <- data[-index, ]
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
data$HeartDisease <- factor(data$HeartDisease)
# On sépare les données en partie pour l'entrainement et une pour les tests
pourcentageTraining = 0.9
nSamples = nrow(data)
#set.seed(123)
index <- sample(1:nrow(data), size = pourcentageTraining * nrow(data), replace = FALSE)
trainData <- data[index, ]
testData <- data[-index, ]
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
#Chargement du jeu de données
setwd(".")
data <- read.csv("heart.csv", sep = ",")
total <- length(data$HeartDisease)
counts <- table(data$HeartDisease)
percentages <- counts / total * 100
labels <- paste0(round(percentages, 2), "%")
pie(percentages, col = c("orange","red"), labels = labels, main = "Répartition des pourcentages")
legend("topright", legend = c("No heart disease", "Heart disease"), fill = c("orange","red"))
# Créer une liste de couleurs pour les différentes catégories de la variable cible
colors <- c("green", "red")  # Ajoutez plus de couleurs si nécessaire
# Définir les dimensions du graphique
variables <- c(data$Sex, data$ChestPainType, data$Cholesterol, data$RestingECG)
par(mfrow = c(2, 2))  # Divise le graphique en 3 lignes et 2 colonnes
table_data <- table(data$HeartDisease, data$Sex)
barplot(table_data, beside = TRUE, col = colors,
main = "Sex vs HeartDisease", ylab = "Count")
table_data <- table(data$HeartDisease, data$ChestPainType)
barplot(table_data, beside = TRUE, col = colors,
main = "Chest pain type vs HeartDisease",ylab = "Count")
legend("topright", legend = c("No Heart Disease", "Heart Disease"),
fill = colors)
table_data <- table(data$HeartDisease, data$ST_Slope)
barplot(table_data, beside = TRUE, col = colors,
main = "ST_slope vs HeartDisease", ylab = "Count")
table_data <- table(data$HeartDisease, data$RestingECG)
barplot(table_data, beside = TRUE, col = colors,
main = "Resting ECG vs HeartDisease", ylab = "Count")
# Création de tranches d'âge
data$AgeGroup <- cut(data$Age, breaks = seq(from = min(data$Age), to = max(data$Age), by = 10))
# Calculer le nombre total de personnes par tranche d'âge
total_par_age <- table(data$AgeGroup)
# Filtrer pour ne garder que les personnes malades
data_malade <- subset(data, HeartDisease == 1)
# Calculer le nombre de personnes malades par tranche d'âge
malades_par_age <- table(data_malade$AgeGroup)
# Calculer le ratio de personnes malades par tranche d'âge pour 100 personnes
ratio_malades_par_100 <- (malades_par_age / total_par_age) * 100
# Créer un diagramme à barres pour ces ratios
barplot(ratio_malades_par_100,
main = "Pourcentage de personnes malades par tranche d'âge pour 100 personnes",
xlab = "Tranche d'âge",
ylab = "Pourcentage de malades",
col = "lightblue",
las = 2) # Rotation des étiquettes de l'axe des x
data$Sex <- ifelse(data$Sex == "M", 1, -1)
data$RestingECG <- ifelse(data$RestingECG == "Normal",1,-1)
data$ChestPainType <- ifelse(data$ChestPainType == "ATA", -1,
ifelse(data$ChestPainType == "NAP", 0, 1))
data$ExerciseAngina <- ifelse(data$ExerciseAngina == "Y",1,-1)
data$ST_Slope <- ifelse(data$ST_Slope == "Up", -1,
ifelse(data$ST_Slope == "Flat", 0, 1))
pairs(data, main = "Matrice de Scatter Plots")
#data_mat <- cor(data)
bp = boxplot(data[, -ncol(data)], plot = FALSE)
data_clean = data
for (i in 1:(ncol(data))){
# On a beaucoup moins de femmes que d'hommes donc il faut faire attention à ce que le code ne supprime pas toutes les donnés provenant de patientes
if(names(data_clean[i]) == "Sex"){
next
}
valeurs_aberrantes = bp$out[which(bp$group == i)]
data_clean = data_clean[!data_clean[, i] %in% valeurs_aberrantes, ]
}
for (i in 1:(ncol(data_clean))) {
boxplot(data_clean[, i], main = names(data_clean[i]))
}
rm(i)
#data = data_clean
data$HeartDisease <- factor(data$HeartDisease)
# On sépare les données en partie pour l'entrainement et une pour les tests
pourcentageTraining = 0.9
nSamples = nrow(data)
set.seed(123)
index <- sample(1:nrow(data), size = pourcentageTraining * nrow(data), replace = FALSE)
trainData <- data[index, ]
testData <- data[-index, ]
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR*Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR +ChestPainType + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + 2*ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
# Chargement du package randomForest
library(randomForest)
# Ajustement du modèle Random Forest
# On a enlever les variable age , FastingBS pour diminuer l'erreur
modele_rf <- randomForest(HeartDisease ~ Sex + ChestPainType + Cholesterol + MaxHR + ExerciseAngina + Oldpeak + ST_Slope,
data = data,
ntree = 1500,  # Nombre d'arbres à générer
mtry = 2,      # Nombre de variables testées à chaque division
importance = TRUE,  # Calculer l'importance des variables
type = "classification")  # Spécifier le type de modèle
# Affichage du résumé du modèle
print(modele_rf)
# Pour voir l'importance des variables
importance(modele_rf)
# Chargement du package randomForest
library(randomForest)
# Ajustement du modèle Random Forest
# On a enlever les variable age , FastingBS pour diminuer l'erreur
modele_rf <- randomForest(HeartDisease ~ Sex + ChestPainType * MaxHR+ Cholesterol + ExerciseAngina + Oldpeak + ST_Slope,
data = data,
ntree = 1500,  # Nombre d'arbres à générer
mtry = 2,      # Nombre de variables testées à chaque division
importance = TRUE,  # Calculer l'importance des variables
type = "classification")  # Spécifier le type de modèle
# Affichage du résumé du modèle
print(modele_rf)
# Pour voir l'importance des variables
importance(modele_rf)
# Chargement du package randomForest
library(randomForest)
# Ajustement du modèle Random Forest
# On a enlever les variable age , FastingBS pour diminuer l'erreur
modele_rf <- randomForest(HeartDisease ~ Sex + ChestPainType: MaxHR+ Cholesterol + ExerciseAngina + Oldpeak + ST_Slope,
data = data,
ntree = 1500,  # Nombre d'arbres à générer
mtry = 2,      # Nombre de variables testées à chaque division
importance = TRUE,  # Calculer l'importance des variables
type = "classification")  # Spécifier le type de modèle
# Affichage du résumé du modèle
print(modele_rf)
# Pour voir l'importance des variables
importance(modele_rf)
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ST_Slope * MaxHR + Cholesterol +ChestPainType+ ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ST_Slope * MaxHR + Cholesterol +ChestPainType+ ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
# Chargement du package randomForest
library(randomForest)
# Ajustement du modèle Random Forest
# On a enlever les variable age , FastingBS pour diminuer l'erreur
modele_rf <- randomForest(HeartDisease ~ Sex + ChestPainType + MaxHR+ Cholesterol + ExerciseAngina + Oldpeak + ST_Slope,
data = data,
ntree = 1500,  # Nombre d'arbres à générer
mtry = 2,      # Nombre de variables testées à chaque division
importance = TRUE,  # Calculer l'importance des variables
type = "classification")  # Spécifier le type de modèle
# Affichage du résumé du modèle
print(modele_rf)
# Pour voir l'importance des variables
importance(modele_rf)
#Chargement du jeu de données
setwd(".")
data <- read.csv("heart.csv", sep = ",")
memory.limit(size=12000)
library(doParallel)
library(foreach)
# Détecter le nombre de cœurs disponibles
no_cores <- detectCores() - 2  # Garder un cœur libre pour le système
# Enregistrer le backend parallèle à utiliser avec foreach
registerDoParallel(cores = no_cores)
#modele_logistique <- glm(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + Cholesterol + FastingBS + RestingECG + MaxHR + ExerciseAngina + Oldpeak + ST_Slope, data = data, family = binomial(link = "logit"))
#print(summary(modele_logistique))
#observation_weights <- rep(1, nrow(trainData))
#print(observation_weights)
# On peux noter que fastingBS a une faible incidence sur les résultats
modele_logistique <- glm(HeartDisease ~  Sex + ChestPainType * MaxHR + Cholesterol + ExerciseAngina + Oldpeak + ST_Slope, data = trainData, family = binomial(link = "logit")) #,weights = observation_weights)
#print(summary(modele_logistique))
predictions <- predict(modele_logistique,newdata = testData, type = "response")
class_pred <- ifelse(predictions > 0.5, 1, 0)
#print(class_pred)
res <- table(Predicted = class_pred, Actual = testData$HeartDisease)
#print(res)
erreur_classification <- sum(res[1,2], res[2,1]) / sum(res)
print(erreur_classification)
